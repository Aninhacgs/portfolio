{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JornadaPython_Classificação Binária - Diabetes.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mE4-PIaTAfKX",
        "f2OGe0DtAfU4"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tatianaesc/portfolio/blob/master/JornadaPython_Classifica%C3%A7%C3%A3o_Bin%C3%A1ria_Diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otEdveLq8Hn0",
        "colab_type": "text"
      },
      "source": [
        "# Jornada Python - Summit de 04/07/20\n",
        "# Machine Learning - Prof. Tatiana Escovedo\n",
        "# Projeto de Classificação Binária com Python e Scikit-Learn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJpWLh52-aPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1PEQEdZ9zm4",
        "colab_type": "text"
      },
      "source": [
        "## 1. Definição do Problema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCn8CH4M7wF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler # para padronização\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PcB0Efd-MS4",
        "colab_type": "text"
      },
      "source": [
        "## 2. Carga de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29AFuCPtvG_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carrega arquivo csv usando Pandas usando uma URL\n",
        "\n",
        "# Informa a URL de importação do dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "\n",
        "# Informa o cabeçalho das colunas\n",
        "colunas = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "\n",
        "# Lê o arquivo utilizando as colunas informadas\n",
        "dataset = pd.read_csv(url, names=colunas, skiprows=0, delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBSgQt_z_TnV",
        "colab_type": "text"
      },
      "source": [
        "## 3. Análise de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqINv-wo_Xfe",
        "colab_type": "text"
      },
      "source": [
        "### 3.1. Estatísticas Descritivas\n",
        "\n",
        "Vamos iniciar examinando as dimensões do dataset, suas informações e alguns exemplos de linhas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUjmUTEOwQZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mostra as informações do dataset\n",
        "print(dataset.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPy9N4FuwX6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mostra as 10 primeiras linhas do dataset\n",
        "dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NKdYewownzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Faz um resumo estatístico do dataset (média, desvio padrão, mínimo, máximo e os quartis)\n",
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j0Pa0W__tOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# distribuição das classes\n",
        "print(dataset.groupby('class').size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_5Ntt3f_tTv",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. Visualizações\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHUaJJNK_tji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Density Plot\n",
        "dataset.plot(kind = 'density', subplots = True, layout = (3,3), sharex = False, figsize = (15,10))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctc5ftKgxurF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Boxplot\n",
        "dataset.plot(kind = 'box', subplots = True, layout = (3,3), sharex = False, sharey = False, figsize = (15,10))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB612g0aAfE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Matriz de Correlação com Matplotlib Seaborn\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(dataset.corr(), annot=True, cmap='RdBu');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0seViuUy_Gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scatter Plot e Density plot\n",
        "\n",
        "sns.pairplot(dataset, hue = \"class\", height = 2.5);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE4-PIaTAfKX",
        "colab_type": "text"
      },
      "source": [
        "## 4. Pré-Processamento de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoLQBjKl9JVD",
        "colab_type": "text"
      },
      "source": [
        "### 4.1. Separação em conjunto de treino e conjunto de teste\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEiAm3LEAfPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separação em conjuntos de treino e teste\n",
        "array = dataset.values\n",
        "X = array[:,0:8].astype(float)\n",
        "Y = array[:,8]\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
        "    test_size=0.20, random_state=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2OGe0DtAfU4",
        "colab_type": "text"
      },
      "source": [
        "## 5. Modelos de Classificação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Foy4MFlSAfaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parâmetros\n",
        "num_folds = 10\n",
        "scoring = 'accuracy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwHzQpbX9QQh",
        "colab_type": "text"
      },
      "source": [
        "### 5.1. Criação e avaliação de modelos: linha base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAhfSnnIAfke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criação dos modelos\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression(solver='liblinear'))) \n",
        "models.append(('KNN', KNeighborsClassifier())) \n",
        "models.append(('CART', DecisionTreeClassifier())) \n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC(gamma='auto')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUUqbS2fBQrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(7) # definindo uma semente global\n",
        "\n",
        "# Avaliação dos modelos\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "  kfold = KFold(n_splits=10)\n",
        "  cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  print(msg)\n",
        "\n",
        "# Comparação dos modelos\n",
        "fig = plt.figure() \n",
        "fig.suptitle('Comparação dos Modelos') \n",
        "ax = fig.add_subplot(111) \n",
        "plt.boxplot(results) \n",
        "ax.set_xticklabels(names) \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olo7SPk2BvvW",
        "colab_type": "text"
      },
      "source": [
        "### 5.2. Criação e avaliação de modelos: dados padronizados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmQbiYQdBRDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(7) # definindo uma semente global\n",
        "\n",
        "# Padronização do dataset\n",
        "pipelines = []\n",
        "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR', LogisticRegression(solver='liblinear'))]))) \n",
        "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsClassifier())])))\n",
        "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeClassifier())])))\n",
        "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()),('NB', GaussianNB())])))\n",
        "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()),('SVM', SVC(gamma='auto'))])))\n",
        "results = []\n",
        "names = []\n",
        "for name, model in pipelines:\n",
        "  kfold = KFold(n_splits=num_folds)\n",
        "  cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  print(msg)\n",
        "\n",
        "# Comparação dos modelos com dados padronizados\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparação dos modelos com dados padronizados') \n",
        "ax = fig.add_subplot(111) \n",
        "plt.boxplot(results) \n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-f2vCU5CMmp",
        "colab_type": "text"
      },
      "source": [
        "### 5.3. Ajuste dos Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwaWY9UuxNpA",
        "colab_type": "text"
      },
      "source": [
        "#### Ajuste do KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwI7Cxc-CZdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(7) # definindo uma semente global\n",
        "\n",
        "# Tuning do KNN\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "rescaledX = scaler.transform(X_train)\n",
        "\n",
        "k = [1,3,5,7,9,11,13,15,17,19,21]\n",
        "distancias = [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
        "param_grid = dict(n_neighbors=k, metric=distancias)\n",
        "\n",
        "model = KNeighborsClassifier()\n",
        "\n",
        "kfold = KFold(n_splits=10)\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
        "grid_result = grid.fit(rescaledX, Y_train)\n",
        "print(\"Melhor: %f usando %s\" % (grid_result.best_score_, grid_result.best_params_)) \n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f): %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFhy-staCmo8",
        "colab_type": "text"
      },
      "source": [
        "#### Ajuste do SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YvUNoSECsAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(7) # definindo uma semente global\n",
        "\n",
        "# Tuning do SVM\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "rescaledX = scaler.transform(X_train)\n",
        "\n",
        "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
        "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "param_grid = dict(C=c_values, kernel=kernel_values)\n",
        "\n",
        "model = SVC(gamma='auto')\n",
        "\n",
        "kfold = KFold(n_splits=10)\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
        "grid_result = grid.fit(rescaledX, Y_train)\n",
        "print(\"Melhor: %f usando %s\" % (grid_result.best_score_, grid_result.best_params_)) \n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(\"%f (%f): %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuUpaYcwDRDt",
        "colab_type": "text"
      },
      "source": [
        "## 6. Finalização do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbrFxAbSDVIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparação do modelo\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "rescaledX = scaler.transform(X_train)\n",
        "model = SVC(C=0.1, kernel='linear')\n",
        "model.fit(rescaledX, Y_train)\n",
        "\n",
        "# Estimativa da acurácia no conjunto de teste\n",
        "rescaledTestX = scaler.transform(X_test)\n",
        "predictions = model.predict(rescaledTestX)\n",
        "print(accuracy_score(Y_test, predictions))\n",
        "print(confusion_matrix(Y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}